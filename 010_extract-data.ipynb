{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обработка персональных данных\n",
    "\n",
    "Записи, относящиеся к каждому \"участнику\" проекта, собраны теперь в текстовых файлах. Для простоты будем называть их блогами. В них по-прежнему много лишних строк. Нужно извлечь из блогов следующую информацию:\n",
    "\n",
    "1) имя автора;\n",
    "2) информацию о его социальных связях, занятиях, месте жительства, возрасте и т.п.\n",
    "\n",
    "Кроме того, нужно разбить блоги на отдельные записи, для каждой определить дату и, по возможности, дополнительные атрибуты (источник и т.п.).\n",
    "\n",
    "Начнем с выявления имени автора. Оно, по предварительным наблюдениям, содержится в первой строке блога, начинающейся со знака `#`. Будем считывать файлы из каталога `data` и, проходя по нит построчно, находить такую строку и ее номер, чтобы не учитывать всё, что идет до нее (информация о проекте в целом, которая нас не интересует)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>person</th>\n",
       "      <th>first_line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nikolaj-duhonin</td>\n",
       "      <td>Николай Духонин</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zinaida-gippius</td>\n",
       "      <td>Зинаида Гиппиус</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ivan-petrunkevich</td>\n",
       "      <td>Иван Петрункевич</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dzhon-henberi-uilyams</td>\n",
       "      <td>Джон Хэнбери-Уильямс</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mark-shagal</td>\n",
       "      <td>Марк Шагал</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               file_name                person  first_line\n",
       "0        nikolaj-duhonin       Николай Духонин          50\n",
       "1        zinaida-gippius       Зинаида Гиппиус          50\n",
       "2      ivan-petrunkevich      Иван Петрункевич          50\n",
       "3  dzhon-henberi-uilyams  Джон Хэнбери-Уильямс          50\n",
       "4            mark-shagal            Марк Шагал          50"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "def find_name(fn, arr):\n",
    "    with open(fn, 'r') as input:\n",
    "       cnt = 0 \n",
    "       for line in input:\n",
    "           if line.startswith('#'):\n",
    "                arr.append((fn.replace('data/', '').replace('.txt', ''), line.replace('#', '').strip(), cnt))\n",
    "                break\n",
    "           cnt +=1 \n",
    "\n",
    "heroes = []\n",
    "\n",
    "[find_name(fn, heroes) for fn in glob.glob(\"data/*.txt\")[:5]]\n",
    "\n",
    "heroes_frame = pd.DataFrame(heroes, columns=['file_name', 'person', 'first_line'])\n",
    "heroes_frame.head()\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь необходимо пройтись по строкам каждого файла и удалить те, которые не несут полезной информации, а также пометить те, которые указывают на даты постов, источники и т.п."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text  \\\n",
      "0                                 #  Николай Духонин    \n",
      "16                                    Возраст: **40**   \n",
      "20  Юрий Готье Историк, профессор кафедры русской ...   \n",
      "21                                            Москва    \n",
      "22                                           05.12.17   \n",
      "\n",
      "                                             stripped  \n",
      "0                                  #  Николай Духонин  \n",
      "16                                    Возраст: **40**  \n",
      "20  Юрий Готье Историк, профессор кафедры русской ...  \n",
      "21                                             Москва  \n",
      "22                                           05.12.17  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as nm\n",
    "\n",
    "trash_full_words = ['**__Без вымысла __**', '\\-', 'Читать с начала', 'ВКонтакте', 'Фейсбук', 'Твиттер', 'ОК', 'Telegram', 'WhatsApp', 'Viber', 'Скопировать ссылку', 'Вы подписаны']\n",
    "trash_start_words = ['Проект начинается 14 ноября', '**Проект 1917**', 'Подпишитесь на героя', 'Подписаться Вы']\n",
    "trash_contains_words = ['Календарь героя']\n",
    "trash_end_words = ['Поделиться']\n",
    "\n",
    "def is_trash(txt):\n",
    "    if txt in trash_words:\n",
    "        return 'a'\n",
    "    return 'b'\n",
    "\n",
    "def pure_person(i, sr):\n",
    "    file_name = heroes_frame.iloc[i]['file_name']\n",
    "    file_name = 'data/{}.txt'.format(file_name)\n",
    "    df = pd.read_csv(file_name, skiprows=sr, sep='|', header=None)\n",
    "    df.columns = ['text']\n",
    "    df['stripped'] = df['text'].str.strip()\n",
    "    for word in trash_full_words:\n",
    "        df = df.drop(df[df['stripped'].str.strip() == word].index)\n",
    "    for word in trash_start_words:\n",
    "        df = df.drop(df[df['stripped'].str.startswith(word)].index)\n",
    "    for word in trash_contains_words:\n",
    "        df = df.drop(df[df['stripped'].str.contains(word)].index)\n",
    "    for word in trash_end_words:\n",
    "        df = df.drop(df[df['stripped'].str.endswith(word)].index)\n",
    "    print(df.head())\n",
    "\n",
    "pure_person(0, 50)    \n",
    "\n",
    "#for i in range(len(heroes_frame)):    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
